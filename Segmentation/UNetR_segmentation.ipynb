{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03240862-534b-4958-a1d7-7e77d615e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665aad63-75f2-465c-a56b-985a9e66f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from math import log2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = L.Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = L.Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = L.Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = L.Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = L.LayerNormalization()(x)\n",
    "    x = L.MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = L.Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = L.LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = L.Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block(x, num_filters, kernel_size=3):\n",
    "    x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def deconv_block(x, num_filters, strides=2):\n",
    "    x = L.Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=strides)(x)\n",
    "    return x\n",
    "\n",
    "def build_unetr_2d(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = L.Input(input_shape) ## (None, 196, 768)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = L.Dense(cf[\"hidden_dim\"])(inputs) ## (None, 196, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) \n",
    "    pos_embed = L.Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    x = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Transformer encoder\"\"\"\n",
    "    skip_connection_index = [3, 6, 9, 12]\n",
    "    skip_connections = []\n",
    "\n",
    "    for i in range(1, cf[\"num_layers\"]+1, 1):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "        if i in skip_connection_index:\n",
    "            skip_connections.append(x)\n",
    "\n",
    "    \"\"\" CNN Decoder \"\"\"\n",
    "    z3, z6, z9, z12 = skip_connections\n",
    "\n",
    "    ## Reshaping\n",
    "    z0 = L.Reshape((cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"]))(inputs)\n",
    "\n",
    "    shape = (\n",
    "        cf[\"image_size\"]//cf[\"patch_size\"],\n",
    "        cf[\"image_size\"]//cf[\"patch_size\"],\n",
    "        cf[\"hidden_dim\"]\n",
    "    )\n",
    "    z3 = L.Reshape(shape)(z3)\n",
    "    z6 = L.Reshape(shape)(z6)\n",
    "    z9 = L.Reshape(shape)(z9)\n",
    "    z12 = L.Reshape(shape)(z12)\n",
    "\n",
    "\n",
    " ## Decoder 1\n",
    "    x = deconv_block(z12, 512) #input=z12layer;no of filters=512\n",
    "\n",
    "    s = deconv_block(z9, 512)\n",
    "    s = conv_block(s, 512)\n",
    "    x = L.Concatenate()([x, s])\n",
    "\n",
    "    x = conv_block(x, 512)\n",
    "    x = conv_block(x, 512)\n",
    "\n",
    "    ## Decoder 2\n",
    "    x = deconv_block(x, 256)\n",
    "\n",
    "    s = deconv_block(z6, 256)\n",
    "    s = conv_block(s, 256)\n",
    "    s = deconv_block(s, 256)\n",
    "    s = conv_block(s, 256)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 256)\n",
    "    x = conv_block(x, 256)\n",
    "\n",
    "    ## Decoder 3\n",
    "    x = deconv_block(x, 128)\n",
    "\n",
    "    s = deconv_block(z3, 128)\n",
    "    s = conv_block(s, 128)\n",
    "    s = deconv_block(s, 128)\n",
    "    s = conv_block(s, 128)\n",
    "    s = deconv_block(s, 128)\n",
    "    s = conv_block(s, 128)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 128)\n",
    "\n",
    "    ## Decoder 4\n",
    "    x = deconv_block(x, 64)\n",
    "\n",
    "    s = conv_block(z0, 64)\n",
    "    s = conv_block(s, 64)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 64)\n",
    "\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = L.Conv2D(1, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"UNETR_2D\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"image_size\"] = 224\n",
    "    config[\"num_layers\"] = 12\n",
    "    config[\"hidden_dim\"] = 768\n",
    "    config[\"mlp_dim\"] = 3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"patch_size\"] = 16\n",
    "    config[\"num_patches\"] = (config[\"image_size\"]**2)//(config[\"patch_size\"]**2)\n",
    "    config[\"num_channels\"] = 3\n",
    "\n",
    "    model = build_unetr_2d(config)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36b3b5-6e68-4bdf-adfc-23add78e8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify\n",
    "# from unetr_2d import build_unetr_2d\n",
    "# from metrics import dice_loss, dice_coef\n",
    "\n",
    "\n",
    "\"\"\" UNETR  Configration \"\"\"\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 224\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12\n",
    "cf[\"hidden_dim\"] = 768\n",
    "cf[\"mlp_dim\"] = 3072\n",
    "cf[\"num_heads\"] = 12\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    ")\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path, split=0.2):\n",
    "    \"\"\" Loading the images and masks \"\"\"\n",
    "    X = sorted(glob(os.path.join(path, \"images1\", \"*.png\")))\n",
    "    Y = sorted(glob(os.path.join(path, \"masks1\", \"*.png\")))\n",
    "\n",
    "    \"\"\" Spliting the data into training and testing \"\"\"\n",
    "    split_size = int(len(X) * split)\n",
    "\n",
    "    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    \"\"\" Processing to patches \"\"\"\n",
    "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n",
    "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    mask = mask / 255.0\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape(cf[\"flat_patches_shape\"])\n",
    "    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
    "    return ds\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 8\n",
    "    lr = 0.1\n",
    "    num_epochs = 100\n",
    "    model_path = os.path.join(\"models\", \"model.keras\")\n",
    "    csv_path = os.path.join(\"models\", \"log.csv\")\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"segmentation-dataset/Data\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = build_unetr_2d(cf)\n",
    "    model.compile(loss=dice_loss, optimizer=SGD(lr), metrics=[dice_coef, \"acc\"])\n",
    "    # model.summary()\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ecd5f-36b4-4277-8ead-3e4d5f4741fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from patchify import patchify\n",
    "# from train import load_dataset, create_dir\n",
    "# from metrics import dice_loss, dice_coef\n",
    "\n",
    "\n",
    "\"\"\" UNETR  Configration \"\"\"\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 224\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12 \n",
    "cf[\"hidden_dim\"] = 768 \n",
    "cf[\"mlp_dim\"] = 3072\n",
    "cf[\"num_heads\"] = 12\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2)//(cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"]\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(f\"results\")\n",
    "\n",
    "    \"\"\" Load the model \"\"\"\n",
    "    model_path = os.path.join(\"models\", \"model.keras\")\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coef\": dice_coef})\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"segmentation-dataset/Data\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[-1]\n",
    "\n",
    "        \"\"\" Reading the image \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "        x = image / 255.0\n",
    "\n",
    "        patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "        patches = patchify(x, patch_shape, cf[\"patch_size\"])\n",
    "        patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "        patches = patches.astype(np.float32)\n",
    "        patches = np.expand_dims(patches, axis=0)\n",
    "\n",
    "        \"\"\" Read Mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "        pred = model.predict(patches, verbose=0)[0]\n",
    "        pred = np.concatenate([pred, pred, pred], axis=-1)\n",
    "\n",
    "        \"\"\" Save final mask \"\"\"\n",
    "        line = np.ones((cf[\"image_size\"], 10, 3)) * 255\n",
    "        cat_images = np.concatenate([image, line, mask*255, line, pred*255], axis=1)\n",
    "        save_image_path = os.path.join(\"results\",  name)\n",
    "        cv2.imwrite(save_image_path, cat_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
